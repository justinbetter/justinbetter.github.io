<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>技术 on Blog of Justin</title>
    <link>https://justinbetter.github.io/%E6%8A%80%E6%9C%AF/</link>
    <description>Recent content in 技术 on Blog of Justin</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 15 Jul 2019 20:00:22 +0800</lastBuildDate>
    
	<atom:link href="https://justinbetter.github.io/%E6%8A%80%E6%9C%AF/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>mysql连招</title>
      <link>https://justinbetter.github.io/%E6%8A%80%E6%9C%AF/mysql/</link>
      <pubDate>Sat, 05 Sep 2020 20:00:22 +0800</pubDate>
      
      <guid>https://justinbetter.github.io/%E6%8A%80%E6%9C%AF/mysql/</guid>
      <description>[TOC]
关键词 B树，B+树，红黑树，联合索引存储 主从复制，宕机恢复，8.0相比5.0的改进 事务，隔离级别，实现原理，MVCC 在线改表原理，redolog,undolog,binlog，group commit原理问题解决 零拷贝的场景，主键自增id而不是uuid 什么场景使用索引不使用更慢， 锁的数据结构 分库分表扩容，当nosql，开发mysql引擎如何接口对接 死锁，  谈谈主从复制 复制（replication）是MySQL数据库提供的一种高可用高性能的解决方案，一般用来建立大型的应用。 replication的工作原理分为以下3个步骤：
1）主服务器（master）把数据更改记录到二进制日志（binlog）中。
2）从服务器（slave）把主服务器的二进制日志复制到自己的中继日志（relay log）中。
从服务器有2个线程，一个是I/O线程，负责读取主服务器的二进制日志，并将其保存为中继日志；另一个是SQL线程，复制执行中继日志  3）从服务器重做中继日志中的日志，把更改应用到自己的数据库上，以达到数据的最终一致性
异步实时 中间存在主从服务器之间的执行延时，如果主服务器的压力很大，则可能导致主从服务器延时较大
事务 在事务中的操作，要么都做修改，要么都不做 分类：扁平、带有保存点、链事务、嵌套事务、分布式事务
原子性、一致性、持久性通过数据库的redo log和undo log来完成。 redo log称为重做日志，用来保证事务的原子性和持久性。 undo log用来保证事务的一致性
redo log：两部分组成 一是内存中的重做日志缓冲（redo log buffer），其是易失的；
二是重做日志文件（redo log file），其是持久的
binlog
二进制日志（binlog），其用来进行POINT-IN-TIME（PIT）的恢复及主从复制（Replication）环境的建 redo 区别： 产生：redo是在innodb，binlog是在mysql上层 内容：redo是物理格式日志，记录页修改；binlog是逻辑日志，记录SQL语句 写入时间：redo事务中不断写入，binlog事务提交时写入
恢复：
innodb每次启动都会恢复重做日志 redolog，checkpoint表示已经刷新到磁盘页上的LSN，从checkpoint中开始部分即可
undo：
回滚日志，数据修改时会产生，存放在共享表空间的一个段中 MVCC控制，当用户读取一行记录时，若该记录已经被其他事务占用，当前事务可以通过undo读取之前的行版本信息，以此实现非锁定读取 undo log会产生redo log，也就是undo log的产生会伴随着redo log的产生，这是因为undo log也需要持久性的保护
purge：
因为存在MVCC，决定最终是否删除，如果没被任何事务引用，可以删除，之前的删除只是改了个标志 执行清理时，historyList 找undo log 然后再从undo page中找undo log，避免大量随机读写 太长了通过延时操作解决</description>
    </item>
    
    <item>
      <title>redis连招</title>
      <link>https://justinbetter.github.io/%E6%8A%80%E6%9C%AF/redis/</link>
      <pubDate>Sat, 05 Sep 2020 20:00:22 +0800</pubDate>
      
      <guid>https://justinbetter.github.io/%E6%8A%80%E6%9C%AF/redis/</guid>
      <description>[TOC]
关键字 单线程，epoll，cluster，sentinel，gossip，raft， 分布式锁，穿透，击穿，雪崩，数据一致性， sds，ziplist，skiplist，rehash，hyperloglog， 热key，大key，过期清理，淘汰策略，主从复制，rdb，aof，aof rewrite string,hash,set,zset的底层数据结构实现，hash的渐进式扩容 hyperloglog标准误差多少，原理是啥 再加上 6.0之后的加入的多线程 工作机制 缓存过期重置。锁刷新 一致性哈希算法  分布式锁 setnx讲起，最后慢慢引出set命令的可以加参数， setnx 是SET if Not eXists(如果不存在，则 SET)的简写。万一set value 成功 set time失败 setex是一个原子性(atomic)操作，关联值和设置生存时间两个动作会在同一时间内完成。 redisson的锁，就实现了可重入，他使用了LUA的Hash数据结构。
cluster Redis集群是Redis提供的分布式数据库方案，集群通过分片（sharding）来进行数据共享，并提供复制和故障转移功能。
自动将数据进行分片，每个 master 上放一部分slot数据 提供内置的高可用支持，部分 master 不可用时，还是可以继续工作的 维护数据采用的是gossip协议
节点发现原理： 发送CLUSTER MEET命令握手，meet-pong-ping 握手完成 节点A会将节点B的信息通过Gossip协议传播给集群中的其他节点，让其他节点也与节点B进行握手，
最终，经过一段时间之后，节点B会被集群中的所有节点认识。 gossip 协议，Gossip协议由MEET、PING、PONG，FAIL种消息实现 每次发送MEET、PING、PONG消息时，发送者都从自己的已知节点列表中随机选出几个节点（可以是主节点或者从节点），并将这两个被选中节点的信息分别保存到两个clusterMsgDataGossip结构里面。
所有节点都持有一份元数据，不同的节点如果出现了元数据的变更，就不断将元数据发送给其它的节点，让其它节点也进行元数据的变更。 gossip有一定延迟，因为节点是逐步传播的
Redis集群通过分片的方式来保存数据库中的键值对：集群的整个数据库被分为16384个槽（slot）
数据库中的每个键都属于这16384个槽的其中一个，集群中的每个节点可以处理0个或最多16384个槽。 当每个slot 都有节点处理的时候，集群才算上线；CRC16（key），MOVED错误重定向到正确节点 跳跃表来保存槽和键之间的关系
主从复制：主节点用于处理槽，而从节点则用于复制某个主节点，替补上线；
（复制：slaveof命令，发送地址-socket连接-ping-pong-replconf-psync） 原理：master负责写，异步同步slave；，从服务器将向主服务器发送PSYNC命令，执行同步操作，
PSYNC命令具有完整重同步（full resynchronization）和部分重同步（partialresynchronization）两种模式： 开启后台线程生成RDB，同时将从客户端收到的所有写命令缓存在内存（内存缓冲区），
RDB完成后 master发送给slave，slave写入本地磁盘，再从本地磁盘加载到内存中。然后master会将内存中缓存的写命令发送给slave，slave也会同步这些数据。
故障转移： 检测：定期发送ping检测在线，没有在规定时间返回pong消息，标记为pfail，超过半数节点标记，标记fail 转移：选择从节点，选举主节点，转移slot，集群广播自己为主节点 选举：选举新主节点和Sentinel的方法非常相似，两者都是基于Raft算法
哨兵 Redis的高可用性（high availability）解决方案 监视主从节点，执行故障转移</description>
    </item>
    
    <item>
      <title>算法题目汇总</title>
      <link>https://justinbetter.github.io/%E6%8A%80%E6%9C%AF/leetcode/</link>
      <pubDate>Sat, 15 Aug 2020 20:00:22 +0800</pubDate>
      
      <guid>https://justinbetter.github.io/%E6%8A%80%E6%9C%AF/leetcode/</guid>
      <description>归并排序 public class MergeSort { public static void merge(int[] a, int low, int mid, int high) { int[] temp = new int[high - low + 1]; int i = low;// 左指针  int j = mid + 1;// 右指针  int k = 0; // 把较小的数先移到新数组中  while (i &amp;lt;= mid &amp;amp;&amp;amp; j &amp;lt;= high) { if (a[i] &amp;lt; a[j]) { temp[k++] = a[i++]; } else { temp[k++] = a[j++]; } } // 把左边剩余的数移入数组  while (i &amp;lt;= mid) { temp[k++] = a[i++]; } // 把右边边剩余的数移入数组  while (j &amp;lt;= high) { temp[k++] = a[j++]; } // 把新数组中的数覆盖nums数组  for (int k2 = 0; k2 &amp;lt; temp.</description>
    </item>
    
    <item>
      <title>写python脚本常用的函数</title>
      <link>https://justinbetter.github.io/%E6%8A%80%E6%9C%AF/python-learn2/</link>
      <pubDate>Fri, 09 Aug 2019 20:00:22 +0800</pubDate>
      
      <guid>https://justinbetter.github.io/%E6%8A%80%E6%9C%AF/python-learn2/</guid>
      <description>@[toc] #python 脚本常用函数
这里记录一些脚本常用的函数
##文件操作
 路径相关  os.chdir(dst_dir)	#改变当前目录 os.listdir()	#遍历文件夹 for root, dirs, files in os.walk(rootDir): #遍历文件夹 os.path.basename() #去掉目录路径, 返回文件名 os.path.splitext() #返回 (filename, extension) 元组 os.path.exists()	#文件存在	shutil.rmtree(zip_comoress_dir) #删除目录 shutil.copy(source_dir, dst_dir)	#复制文件 os.path.dirname(os.path.realpath(__file__)) #获取当前目录  文件信息  json.dumps(mock_config, indent=5)	#获取json数据 os.path.getsize() #获取文件大小 with open(zip_url,&#39;rb&#39;) as f_zip: #解压zip zip_file = zipfile.ZipFile(f_zip) zip_file.extractall(&#39;./zip&#39;) ---------------------------------------- def get_file_md5(f): #获取MD5 m = hashlib.md5() while True: data = f.read(10240) if not data: break m.update(data) return m.</description>
    </item>
    
    <item>
      <title>python基础</title>
      <link>https://justinbetter.github.io/%E6%8A%80%E6%9C%AF/python-learn/</link>
      <pubDate>Thu, 08 Aug 2019 20:00:22 +0800</pubDate>
      
      <guid>https://justinbetter.github.io/%E6%8A%80%E6%9C%AF/python-learn/</guid>
      <description>[TOC]
基础 继承： “定义子类时，必须在括号内指定父类的名称。” class ElectricCar(Car):
“类名应采用驼峰命名法 ，即将类名中的每个单词的首字母都大写，而不使用下划线。实例名和模块名都采用小写格式，并在单词之间加上下划线。”
输出输入  print() input()  ###数据类型
 整数 浮点数 字符串 布尔值 空值 None 变量 常量  ###字符编码
 UTF-8编码把一个Unicode字符根据不同的数字大小编码成1-6个字节，常用的英文字母被编码成1个字节，汉字通常是3个字节，只有很生僻的字符才会被编码成4-6个字节。如果你要传输的文本包含大量英文字符，用UTF-8编码就能节省空间 ord() 获取整数表示 chr() 编码转化为字符 encode(&amp;lsquo;ascii&amp;rsquo;) str编码为指定的byte作为网络传输 decode(&amp;lsquo;utf-8&amp;rsquo;) byte变为str读取网络字节流 len() 格式化 %d %f %s %x  list 和tuple   list [1,3,2]
 len() append() insert() pop()    tuple 另一种有序列表，一经初始化不能修改
 (1,) 和list的区别就是不可变    ###条件判断
 if : &amp;hellip;elif:&amp;hellip; else:&amp;hellip;. ###循环 for.</description>
    </item>
    
    <item>
      <title>git常用规范</title>
      <link>https://justinbetter.github.io/%E6%8A%80%E6%9C%AF/git-common/</link>
      <pubDate>Mon, 15 Jul 2019 20:00:22 +0800</pubDate>
      
      <guid>https://justinbetter.github.io/%E6%8A%80%E6%9C%AF/git-common/</guid>
      <description>分支规范 - 分支规范 1. 分支命名规范： - master: 主线分支 - feature/xxxx: 功能需求开发分支 - hotfix/xxxx: bug 修复分支 - refactor/xxxx: 重构分支 2. 默认从主线分支 checkout 出功能需求 or bug 修复分支 3. 分支合并需要写清本次开发的内容点 - Commit Message 规范 1. 命名规则：func[(main)]: done something - 其中 `[ ]` 中的内容可以省略 2. func 规则： 1. feat: 新功能开发 2. fix: bug 修复 3. refactor: 不影响现有功能的重构 4. test: 添加测试 5. chore: 构建工具改动 6. style: 格式改动 3. 冒号（英文冒号，并空一格）后面写上这次 commit 提交的内容，最好一个小功能点一次提交 4. 禁止类似 `update` 这样无意义的提交！ 查看当前url git remote -v git remote set-url origin [url] git remote rm origin git remote add origin [url] git config user.</description>
    </item>
    
    <item>
      <title>Linux笔记</title>
      <link>https://justinbetter.github.io/%E6%8A%80%E6%9C%AF/linux-post/</link>
      <pubDate>Sat, 15 Jun 2019 20:00:22 +0800</pubDate>
      
      <guid>https://justinbetter.github.io/%E6%8A%80%E6%9C%AF/linux-post/</guid>
      <description>帮助手册命令 man man命令：可以通过一些参数，快速查询linux帮助手册，并且格式化显示。  ##Linux 下修改 root 密码方法 passwd root
权限 chgrp ：改变文件所属群组 chown -R：改变文件拥有者 chmod ：改变文件的权限, SUID, SGID, SBIT等等的特性	su - user1 切换身份user1  查看服务  /etc/services /etc/init.d/ 启动脚本处	/etc/* ：各服务各自的配置文件 service --status-all 查看所有服务  常用目录 /etc 主要配置文件 /bin 常用执行文件 /sbin 重要的系统执行文件 /dev 存放设备文件 /dev/null 垃圾桶 /home 用户目录 /media /mnt 挂载外部装置 /opt 第三方协议软件 习惯放/usr/local /proc 虚拟文件，存放内存数据:系统cpu、网络.. / (root, 根目录)： 与开机系统有关； /usr (unix software resource)：与软件安装/执行有关； /usr/local/ 自己下载的软件安装目录 /var (variable)： 与系统运作过程有关的常态性变动的文件：缓存、log等。 /etc/issue 配置开机画面显示 /etc/motd 配置登录显示 /etc/ssh/sshd_config ssh配置 ~/.</description>
    </item>
    
    <item>
      <title>Kafka机制一览</title>
      <link>https://justinbetter.github.io/%E6%8A%80%E6%9C%AF/kafka/</link>
      <pubDate>Wed, 05 Jun 2019 20:00:22 +0800</pubDate>
      
      <guid>https://justinbetter.github.io/%E6%8A%80%E6%9C%AF/kafka/</guid>
      <description>Kafka： topic、producer、consumer、broker
topic本质就是一个目录,由一些Partition Logs(分区日志)组成（便于集群拓展、提高并发） Kafka需要维持的元数据只有一个–消费消息在Partition中的offset值，Consumer每消费一个消息，offset就会加1。 其实消息的状态完全是由Consumer控制的，Consumer可以跟踪和重设这个offset值，这样的话Consumer就可以读取任意位置的消息
允许用户为每个topic设置副本数量，副本数量决定了有几个broker来存放写入的数据；副本都是以partition为单位的，不过只有一个partition的副本会被选举成leader作为读写用
从Producer端看：Kafka是这么处理的，当一个消息被发送后，Producer会等待broker成功接收到消息的反馈（可通过参数控制等待时间），如果消息在途中丢失或是其中一个broker挂掉，Producer会重新发送（我们知道Kafka有备份机制，可以通过参数控制是否等待所有备份节点都收到消息）。 从Consumer端看：前面讲到过partition，broker端记录了partition中的一个offset值，这个值指向Consumer下一个即将消费message。当Consumer收到了消息，但却在处理过程中挂掉，此时Consumer可以通过这个offset值重新找到上一个消息再进行处理。Consumer还有权限控制这个offset值，对持久化到broker端的消息做任意处理。
为什么快？ 顺序读写、分区、零拷贝、批量发送、数据压缩； 如何提高？生产端调整 batch.size、linger.ms（最多等待时间） 参数，以及主题分区数合理分配等。
存储？ 在Kafka文件存储中，同一个topic下有多个不同partition，每个partition为一个目录，partiton命名规则为topic名称+有序序号 partition目录下Segment file组成：由2大部分组成，分别为index file和data file，此2个文件一一对应，成对出现，后缀”.index”和“.log”分别表示为segment索引文件、数据文件。
生产者机制？ 生产的流程主要就是一个producer线程和一个sender线程，它们之间通过BatchQueue来获取数据，它们的关系是一一对应的，所以kafka的生产过程都是异步过程， 数据最终是放在BatchQueue，像是将水流入了一个蓄水池的场景，这就是蓄水池机制 每条消息先从MetaData里面获取分区信息，再申请一段buffer空间形成一个批接收空间，RecordAccumulator 会将收到的每条消息append到这个buffer中，最后将每个批次压入到队列当中，等待Sender线程来获取发送。 buffer空间 ： BufferPool（缓冲池）对象，整个KafkaProducer实例中只有一个BufferPool对象。内存池总大小，它是已使用空间和可使用空间的总和，内存缓冲池的设计，让整个发送过程中的存储空间循环利用，有效减少JVM GC造成的影响 Sender 是一个发送线程，负责读取记录收集器中缓存的批量消息，经过一些中间转换操作，将要发送的数据准备好，然后交由 Selector 进行网络传输。 https://zhuanlan.zhihu.com/p/137811719
消息是kafka中最基本的数据单元，一条消息由key,value组成，producer往broker中的指定topic中发送一条消息，producer会根据这条消息的key的hashcode值%分区数取模，来确定这个消息分配到那个Partition分区； acks参数指定了必须要有多少个分区副本收到消息，生产者才认为该消息是写入成功的 acks=0，表示生产者在成功写入消息之前不会等待任何来自服务器的响应. acks=1，表示只要集群的leader分区副本接收到了消息，就会向生产者发送一个成功响应的ack， acks =all,表示只有所有参与复制的节点(ISR列表的副本)全部收到消息时，生产者才会接收到来自服务器的响应；延迟高
消费者机制？ Kafka有两种模式消费数据：队列 和发布订阅 ；在队列模式下，一条数据只会发 送给 customer group中的一个 customer 进行消费；在发布订阅模式下，一条数据会发送给多个 customer进行消费。 消费者组，那自然是由消费者组成的，组内可以有一个或多个消费者实例，而这些消费者实例共享一个id，称为group id 一个消费者组中，每一个分区只能由组内的一消费者订阅；消费者组大于分区数多的会空闲 重平衡（Rebalance）其实就是一个协议，它规定了如何让消费者组下的所有消费者来分配topic中的每一个分区；kafka基本处于不可用状态 Kafka的数据是按照分区进行排序(插入的顺序 )，也就是每个分区中的数据有序的，但是多个分区之间做不到全局有序
零拷贝原理： 传统拷贝涉及到用户空间和内核空间的切换，使用DMA可以直接存取内存，不需要CPU调度； 通过DMA直接网卡访问内存，实现零拷贝； 操作系统提供 了一个优化的代码路径，页缓存到socket，linux上是通过 sendfile 系统调用来 Kafka在文件传输的过程中正是使用了零拷贝技术对文件进行拷贝
选举？ quorum（法定人数） quorum是一种在分布式系统中常用的算法，主要用来通过数据冗余来保证数据一致性的投票算法。在kafka中该算法的实现就是ISR，在ISR中就是可以被选举为leader的法定人数。 ISR（in-sync replicas）列表。每个分区的 leader 会维护一个 ISR 列表，ISR 列表里面就是 follower 副本的 Borker 编号，只有跟得上 Leader 的 follower 副本才能加入到 ISR 里面 当 Leader 挂掉了，而且 unclean.</description>
    </item>
    
    <item>
      <title>正则</title>
      <link>https://justinbetter.github.io/%E6%8A%80%E6%9C%AF/regexpression/</link>
      <pubDate>Wed, 18 Jul 2018 20:00:22 +0800</pubDate>
      
      <guid>https://justinbetter.github.io/%E6%8A%80%E6%9C%AF/regexpression/</guid>
      <description>[TOC]
正则 正则表达式(regular expression)描述了一种字符串匹配的模式（pattern）  元字符 一些有特殊含义的字符，帮助建立匹配规则
\ 转义字符 ^ 匹配开始位置 ps：当在一组方括号里使用^是，它表示&amp;quot;非&amp;quot;或&amp;quot;排除&amp;quot;的意思，常常用来剔除某个字符。 $ 匹配结束位置	ps：字符^和$同时使用时，表示精确匹配（字符串与模式一样），分开使用，只匹配字符串首或尾 + 一次或多次 * 0次或多次  ps：
？0次或1次,也可以将默认的贪婪模式转变为非贪婪，例如，对于字符串 &amp;quot;oooo&amp;quot;，&#39;o+?&#39; 将匹配单个 &amp;quot;o&amp;quot;，而 &#39;o+&#39; 将匹配所有 &#39;o&#39;。 （?:pattern) 获取匹配结果，但是不需要存储为分组结果	（?=pattern) 例如，&amp;quot;Windows(?=95|98|NT|2000)&amp;quot;能匹配&amp;quot;Windows2000&amp;quot;中的&amp;quot;Windows&amp;quot;，但不能匹配&amp;quot;Windows3.1&amp;quot;中的&amp;quot;Windows&amp;quot;。 (?!pattern) 例如&amp;quot;Windows(?!95|98|NT|2000)&amp;quot;能匹配&amp;quot;Windows3.1&amp;quot;中的&amp;quot;Windows&amp;quot;，但不能匹配&amp;quot;Windows2000&amp;quot;中的&amp;quot;Windows&amp;quot;。 {n,m} 限定出现次数 *、+限定符都是贪婪的，因为它们会尽可能多的匹配文字，只有在它们的后面加上一个?就可以实现非贪婪或最小匹配。 [^指定字符串] 指的是除指定字符串以外的其他字符串 [] 匹配其中之一，可匹配字符组的一个列表， （） 可作为子匹配进行分组缓存，分组获取的结果可以通过组编号（从1开始）拿出， **\n访问分组的引用**，可以用来去重 x|y 匹配 x 或 y \s 匹配任何空白字符，包括空格、制表符、换页符等 \S 匹配任何非空白字符 \n 匹配一个换行符 \r 匹配一个回车符 . 匹配除换行符 \n 之外的任何单字符 \b 匹配一个单词边界，是不是在单词的首尾；\B 相反 \d 匹配一个数字字符。等价于 [0-9]。 \D 匹配一个非数字字符。等价于 [^0-9]。 \w 匹配字母、数字、下划线。等价于&#39;[A-Za-z0-9_]&#39;。 [a-z] //匹配所有的小写字母 [A-Z] //匹配所有的大写字母 [a-zA-Z] //匹配所有的字母 [0-9] //匹配所有的数字 [0-9\.</description>
    </item>
    
    <item>
      <title>学会写shell脚本</title>
      <link>https://justinbetter.github.io/%E6%8A%80%E6%9C%AF/shell/</link>
      <pubDate>Thu, 01 Mar 2018 20:00:22 +0800</pubDate>
      
      <guid>https://justinbetter.github.io/%E6%8A%80%E6%9C%AF/shell/</guid>
      <description>##shell是什么
 Shell 是一个用C语言编写的程序，它是用户使用Linux的桥梁。 Shell既是一种命令语言，又是一种程序设计语言，这个应用程序提供了一个界面，用户通过这个界面访问操作系统内核的服务。  ##shell脚本是什么
  shell是为shell编写的脚本程序。
  Bash是大多数Linux系统默认的Shell。
 #! 告诉系统其后路径所指定的程序即是解释此脚本文件的Shell程序。 如： #!/bin/bash    运行方法
 第一种： chmod +x ./test.sh #使脚本具有执行 ./test.sh #执行脚本 第二种： /bin/sh test.sh #运行解释器    ##变量
  使用变量
 your_name=&amp;quot;qinjx&amp;quot; echo $your_name echo ${your_name} #花括号可加可不加    设置只读变量
 myUrl=&amp;quot;http://www.w3cschool.cc&amp;quot; readonly myUrl    删除变量 unset
  ##字符串
  获取长度
 string=&amp;quot;abcd&amp;quot; echo ${#string} #输出 长度4    提取字符串</description>
    </item>
    
    <item>
      <title>记录一些kotlin的用法</title>
      <link>https://justinbetter.github.io/%E6%8A%80%E6%9C%AF/kotlin/</link>
      <pubDate>Tue, 18 Jul 2017 20:00:22 +0800</pubDate>
      
      <guid>https://justinbetter.github.io/%E6%8A%80%E6%9C%AF/kotlin/</guid>
      <description>操作符 Elvis 操作符 ?: val a = b?.length ?: -1 安全转换 as？  转型不成功返回 null  null safety var a : String? = null a?.length //a 为null 则pass，不为null 则调用 a!!.length// 抛异常 类型判断符 is 范围操作符 : in for(i in 1..5 step 1){} for (i in 5 downTo 1 step 2){} 多行输入符 &amp;quot;&amp;rdquo;&amp;rdquo;  三个双引号之间的内容将被原样保留  扩展函数  run  调用函数块，块内 this指代调用对象 返回值为最后一行  val result = &amp;quot;haha&amp;quot;.run{ println(this) &amp;quot;I&#39;m result&amp;quot; } println(result) apply  同run，函数块内this 指代该对象 返回值为对象自己  let  函数块内 it 指代该对象 返回值最后一行  also  函数块内it 指代该对象 返回值为对象自己  with  将该对象作为函数参数 this 指代该对象 返回值为最后一行  val result = with（&amp;quot;haha&amp;quot;）{ println(this) &amp;quot;result&amp;quot; } println(result) 修饰符  private 只能被自己所在的文件可见，不能在定义这个类之外的文件中使用 protected 可以被成员自己和继承它的成员可见（比如，类和它的子类） internal 对所在的整个module可见 public 最没有限制的修饰符。这是默认的修饰符  委托属性   一个属性具有一些相同的行为，使用lazy或者observable可以被很有趣地实现重用。而不是一次又一次地去声明那些相同的代码</description>
    </item>
    
    <item>
      <title>常用的设计模式</title>
      <link>https://justinbetter.github.io/%E6%8A%80%E6%9C%AF/designpattern/</link>
      <pubDate>Sun, 28 May 2017 20:00:22 +0800</pubDate>
      
      <guid>https://justinbetter.github.io/%E6%8A%80%E6%9C%AF/designpattern/</guid>
      <description>@[toc] #设计模式
##单例模式
 Double Check Lock  public static Singleton getInstance(){ if(mInstance == null){ synchronized(Singleton.class){ if(mInstance == null){ mInstance = new Singleton(); } } } retuen mInstance; }  静态内部类  public static Singleton getInstance(){ retuen SingletonHolder.sInstance; } private static class SingletonHolder{ private static final Singleton sInstance = new Singleton(); } ​
##Builder模式
 存储参数 设置参数，return this new 对象，传递参数 返回  ##原型模式
 使用  重写clone() 浅拷贝：拷贝对象无法修改原型对象的字段，保证了安全性（除了引用型字段，多以也要拷贝引用性字段） 深拷贝： 对拷贝对象的引用型字段也要拷贝    工厂方法模式 //抽象产品类 public abstract class Dialog(){ public abstract void show(); } public class DialogA extends Dialog{ @Override public void show(){ //showA } } //抽象工厂 public abstract class Factory{ public abstract &amp;lt;T extends Dialog&amp;gt;T createDialog(Class&amp;lt;T&amp;gt; clazz); } public class DialogAFactory extends Factory{ public &amp;lt;T extends Dialog&amp;gt;T createDialog(Class&amp;lt;T&amp;gt; clazz){ Dialog dialog = null; try{ dialog = (Dialog)Class.</description>
    </item>
    
    <item>
      <title>【cs基础】编译器的普及</title>
      <link>https://justinbetter.github.io/%E6%8A%80%E6%9C%AF/cs-code2/</link>
      <pubDate>Sun, 02 Apr 2017 20:00:22 +0800</pubDate>
      
      <guid>https://justinbetter.github.io/%E6%8A%80%E6%9C%AF/cs-code2/</guid>
      <description>##编译器是什么 编译器就是一种翻译程序，一般是将高级语言编写的源代码转化成汇编或者机器码。说白了就是把我们用python,java等各种语言写的程序,翻译成计算机能看懂的二进制指令数据,以便运行.
##编译流程
 source &amp;ndash;&amp;gt; 词法分析 == 各种记号Token stream &amp;ndash;&amp;gt; 语法分析 == 语法树 &amp;ndash;&amp;gt; 语义分析 == 优化后的语法树 &amp;ndash;&amp;gt; 中间代码生成 == 中间代码 &amp;ndash;&amp;gt; 中间代码优化 == 优化后的中间代码 &amp;ndash;&amp;gt; 目标代码生成 == 目标代码 &amp;ndash;&amp;gt; 目标代码优化 == target program
 ##流程详解
  词法分析
 将源代码的标识符、运算符等分割成一个个记号    语法分析
 解析得到的一个个记号，根据语法规则生成一种抽象语法树  [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-kaiAzFVr-1598890932828)(http://pandolia.net/tinyc/images/syntax_tree-2.png)]
  语义分析
 编译器开始对语法树进行一次或多次的遍历，检查程序的语义规则：变量声明、类型匹配..等    IR生成（中间代码，intermediate Representation）
 一般生成的算法是一个递归的算法，递归的遍历语法树，将语法树上的一些节点替换成中间代码块，再根据特定的规则和顺序将这些中间代码块拼装起来。 为什么不直接生成目标代码？增加编译器的开发扩展性；便于对代码优化，中间代码的优化要比直接在目标代码优化难度低得多。    IR优化
 各种优化： 去除冗余代码 优化循环、算术表达式等    目标代码生成</description>
    </item>
    
    <item>
      <title>【cs基础】如何判断算法的好坏</title>
      <link>https://justinbetter.github.io/%E6%8A%80%E6%9C%AF/cs-algorithm/</link>
      <pubDate>Sat, 01 Apr 2017 20:00:22 +0800</pubDate>
      
      <guid>https://justinbetter.github.io/%E6%8A%80%E6%9C%AF/cs-algorithm/</guid>
      <description>@[toc] #算法复杂度
  平时我们说算法的好坏，排除一些软件和硬件上的限制，怎么去衡量这个算法运行的更快呢？这就是Big O notation的作用啦！ ##Big O notation
  Big O notation是一种描述述函数渐进行为的理论，说白了，表达算法的增长趋势，一个算法会渐渐走向快速还是缓慢的表达方式。
  这种渐进表达有三种记号来表示：O、 Θ 和 Ω 记号法。Θ 记号渐进地给出了一个函数的上界和下界，当只有渐近上界时使用 O 记号，当只有渐近下界时使用 Ω 记号。
  譬如：
$T(n)=4n^2+2n+2$
当 n 增大到非常大时，$n^2$ 项将开始占主导地位 , 一般就用$O(n^2)$表示该算法的上界表示算法复杂度。
   ##算法的衡量从两个方向出发：时间复杂度和空间复杂度 ###1. 时间复杂度
 算法完成其执行所需的总时间量 但是！算法执行的时间我们很难真实的估计，只能比较算法语句的执行次数，以此比较时间复杂度  ###2. 空间复杂度
 算法完成其执行所需的计算机存储器的总量 说白了，就是程序执行所需要的内存空间：  指令空间：用于存储已编译版本指令的内存量。 环境堆栈：在函数调用时存储部分执行函数信息的内存量。 数据空间：用于存储所有变量和常量的内存量。 ##怎么做   书读百遍，其义自见。   参考： http://www.cnblogs.com/gaochundong/p/complexity_of_algorithms.html http://www.ehcoo.com/complexity.html</description>
    </item>
    
    <item>
      <title>【cs基础】浮点数的存储</title>
      <link>https://justinbetter.github.io/%E6%8A%80%E6%9C%AF/cs-number/</link>
      <pubDate>Wed, 29 Mar 2017 20:00:22 +0800</pubDate>
      
      <guid>https://justinbetter.github.io/%E6%8A%80%E6%9C%AF/cs-number/</guid>
      <description>#浮点数的存储 ##为什么讨论浮点数
 计算机只能识别二进制，整数转化为二进制没有任何问题。 但是！浮点数有小数点, 计算机怎么识别！必然要有个规范来规定计算机怎么识别吧！这个规范就是国际标准IEEE 754.  ##浮点数的识别规范
  标准规定，任何浮点数的表现形式为
 V= （-1）^S x M x 2^E 符号位S 尾数位M 指数位E    32bit : 符号位1，指数位8，尾数位23
  64bit : 符号位1，指数位11，尾数位52
  尾数位 M 默认总是1.xxx的形式，秉着优化的概念，标准规定保存的时候可以舍弃，读取的时候再加上，这样尾数范围也增加了 1 位
  指数位2^E , E为8，指数范围0~255; E为11，指数范围 0~2047
  但是！指数E可能为负数 也就是说指数范围可能为-127-128了，为了不出现负数，标准规定采用移位存储，保存的E数据就要+127或者+1023；
  比如E = 10，必须保存成10+127=137，即10001001
   （1）E不全为0或不全为1。这时，浮点数就采用上面的规则表示，即指数E的计算值减去127（或1023），得到真实值，再将有效数字M前加上第一位的1。 （2）E全为0。这时，浮点数的指数E等于1-127（或者1-1023），有效数字M不再加上第一位的1，而是还原为0.xxxxxx的小数。这样做是为了表示±0，以及接近于0的很小的数字。 （3）E全为1。这时，如果有效数字M全为0，表示±无穷大（正负取决于符号位s）；如果有效数字M不全为0，表示这个数不是一个数（NaN）。
 ##单精度和双精度误差
 十进制转化为二进制的时候，要是永远除不尽，单精度转换为双精度的时候，位数变少，多余的值被省忽略了，就会产生误差的问题  </description>
    </item>
    
    <item>
      <title>【cs基础】CPU是怎样执行代码的</title>
      <link>https://justinbetter.github.io/%E6%8A%80%E6%9C%AF/cs-code/</link>
      <pubDate>Fri, 17 Mar 2017 20:00:22 +0800</pubDate>
      
      <guid>https://justinbetter.github.io/%E6%8A%80%E6%9C%AF/cs-code/</guid>
      <description>##基础概念
 程序是指令和数据的组合体，被复制到内存才能运行。 内存地址是保存指令和数据的场所，通过地址标记。 CPU 能识别和执行的只有机器语言。  ##CPU 结构 CPU 内部由寄存器、控制器、运算器和时钟四个部分构成，由电流信号相互连通
 寄存器： 保存指令、数据 控制器： 读取内存输入寄存器，控制指令流转 运算器： 运算寄存器中的数据 时钟：发出计时信号，代表运算速度  ##寄存器 程序是把寄存器作为对象来描述的，程序运行就是依赖寄存器的控制。
 存储的内容既可以是指令也可以是数据 数据分为“用于运算的数值”和“表示内存地址的数值”两种。数据种类不同，存储该数值的寄存器也不同   累加寄存器 &amp;ndash;&amp;gt; 运算的数值 基址寄存器和变址寄存器 &amp;ndash;&amp;gt; 表示内存地址的数值 标志寄存器 &amp;ndash;&amp;gt; 运算处理后的CPU的状态 程序计数器 &amp;ndash;&amp;gt; 下一条指令所在内存的地址 栈寄存器 &amp;ndash;&amp;gt; 栈区域的起始地址
 ##程序函数的处理
 机器语言的 call 指令和 return 指令能够解决这个问题。函数调用使用的是 call 指令，而不是跳转指令。在将函数的入口地址设定到程序计数器之前，call 指令会把调用函数后要执行的指令地址存储在名为栈的主存内。函数处理完毕后，再通过函数的出口来执行 return 命令。return 命令的功能是把保存在栈中的地址设定到程序计数器中  ##CPU 处理 CPU 能执行的主要机器语言指令
   数据转送指令 &amp;ndash;&amp;gt; 寄存器和内存、内存和内存、寄存器和外围设备之间的数据读写操作 运算指令 &amp;ndash;&amp;gt; 用累加寄存器执行算术运算、逻辑运算、比较运算和移位运算 跳转指令 &amp;ndash;&amp;gt; 实现条件分支、循环、强制跳转等 call/return指令 &amp;ndash;&amp;gt; 函数的调用/返回调用前的地址  参考： 《程序是怎样跑起来的》一书 http://cs.</description>
    </item>
    
  </channel>
</rss>